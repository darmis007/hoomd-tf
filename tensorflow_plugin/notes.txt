Spawn python subprocess.
Give it memory address which we create in hoomd plugin
It loads net and adds custom op to front
Gives net memory address

Creating the mmap file:

// set fd = -1 to indicate we don't want an underlying file.
// message -> a struct
// m -> the pointer we will pass
message *m = mmap(NULL, sizeof(message), PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANONYMOUS, -1, 0)

//Steps:
1. Determine data type for positions
    -> Array of Scalar4. Type set at compile time defined in HOOMDMath.h
    -> ArrayHandles are used to access them
2. mmap size will be ?
    -> number of particles * sizeof(Scalar4) : must include HOOMDMath.h @ cmake time
3. synchronization will be ?
    -> py3 queues
4. CustomOp will do...?
    -> takes a constant -> memory address from python
    -> for CC -> We use underliyng mmap + memcpy (https://github.com/tensorflow/tensorflow/blob/dcc414587f50673271a31ab767909ec89c956324/tensorflow/core/framework/tensor_testutil.h#L57)
    -> for GPU -> we replace mmap with cudaIpcMemhandle and custom op will load cuda ipcmemory and copy to output tensor 
5. CustomOP will be setup....?
    -> in Python module entry point which is called by multiprocess


// structure

HOOMD Updater (Python & C++):
    init: mmap or cudaipc (C++), start tf manager (Python)
    update: ping tf manager (Python), load output from tf manager into forces (C++)

TF Manager (Python):
    init: start TF session, add custom op to graph, create two scalar tensors #of particles and memory address as inputs to custom op (Python)
    update: run graph in inference mode after ping from updater (python), ping hoomd when completed with forces

CustomOP-reader (C++): -> output must be known at compile time ? -> no only rank I think?. No it's optional!! Doesn't matter
    input-tensor: list of memory addresses (rank 1) ->scalar
    input-tensor: scalar -> shape of output
    update: copy memory address to output tensor
    
CustomOP-writer (C++): -> output is nothing
    input-tensor: force-size
    input-tensor: memory address for output
    update: memcpy to output memory address